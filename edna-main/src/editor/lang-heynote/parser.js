// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "/Z~RcYZ!^}!O!c#V#W!n#W#X$[#X#Y$}#Z#[%m#[#]&`#^#_&r#_#`(Y#`#a(r#a#b)e#d#e*d#f#g,O#g#h,_#h#i-m#j#k.l#l#m&f#m#n.r%&x%&y.x~!cOX~~!fP#T#U!i~!nOU~~!qR#`#a!z#d#e#o#g#h#u~!}P#c#d#Q~#TP#^#_#W~#ZP#i#j#^~#aP#f#g#d~#gP#X#Y#j~#oOT~~#rP#d#e#j~#xQ#[#]$O#g#h#j~$RP#T#U$U~$XP#f#g#o~$_Q#T#U$e#]#^$q~$hP#f#g$k~$nP#h#i#j~$tP#Y#Z$w~$zP#Y#Z#j~%QP#f#g%T~%WP#`#a%Z~%^P#T#U%a~%dP#b#c%g~%jP#Z#[#j~%pQ#c#d%T#f#g%v~%yP#c#d%|~&PP#c#d&S~&VP#j#k&Y~&]P#m#n#j~&cP#h#i&f~&iP#a#b&l~&oP#`#a#j~&uQ#T#U&{#g#h'y~'OP#j#k'R~'UP#T#U'X~'^PT~#g#h'a~'dP#V#W'g~'jP#f#g'm~'pP#]#^'s~'vP#d#e$k~'|Q#c#d(S#l#m#j~(VP#b#c#j~(]P#c#d(`~(cP#h#i(f~(iP#`#a(l~(oP#]#^(S~(uQ#X#Y({#i#j)_~)OP#n#o)R~)UP#X#Y)X~)[P#f#g#j~)bP#T#U#j~)hP#T#U)k~)nQ#f#g)t#h#i*^~)wP#_#`)z~)}P#W#X*Q~*TP#c#d*W~*ZP#k#l(S~*aP#[#]#j~*gR#[#]#o#c#d*p#m#n+l~*sP#k#l*v~*yP#X#Y*|~+PP#f#g+S~+VP#g#h+Y~+]P#[#]+`~+cP#X#Y+f~+iP#`#a&l~+oP#h#i+r~+uP#[#]+x~+{P#c#d(S~,RP#i#j,U~,XQ#U#V&Y#g#h$k~,bT#V#W,q#[#]+`#e#f&l#j#k,}#k#l-a~,tP#T#U,w~,zP#`#a)_~-QP#X#Y-T~-WP#`#a-Z~-^P#h#i#d~-dP#]#^-g~-jP#Y#Z$k~-pS#X#Y-|#c#d&f#g#h.S#m#n.Y~.PP#l#m$k~.VP#l#m#j~.]P#d#e.`~.cP#X#Y.f~.iP#g#h'a~.oP#i#j#d~.uP#T#U&f~.{P%&x%&y/O~/RP%&x%&y/U~/ZOY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
